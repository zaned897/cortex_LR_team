""" TRAIN NAME ENTITY RECOGNITION. Re-train a base model to improve the NER for insurance reports
    Input:
        train data: json file path[string] labeled (content: string , ent: label and position of the entity)
        background model: model path[string] to be re-traiend
        path of resuls: folder were results will be stored
    Output:
        Re-trainded model: binari and json files 

"""

#%%                                 LOAD DEPENDECIES
from __future__ import unicode_literals, print_function
import plac
import random
from pathlib import Path
import spacy
from tqdm import tqdm
import json
import logging
from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_fscore_support
from spacy.gold import GoldParse
from spacy.scorer import Scorer
from sklearn.metrics import accuracy_score
import sys, getopt 
import time


#                                CATCH THE OPTIONS
args_list = sys.argv[1:]    # options: file to process, path to nlp model and database available?
args_flags = 'ht:m:o:'      # short options
args_long = ['help', 'training-data=','model=', 'output-dir='] # long format for options
argv = sys.argv[1:]         # ignore the first arg since is the script.py opt

try:
   argument, values = getopt.getopt(args_list, args_flags, args_long)
except getopt.error as err: 
    print(str(err) + ', system exit...')
    sys.exit(2)            # there are an error with the input then exit



#%% Set the default options
model = 'en_core_web_sm'
output_dir=Path('home/app/models/base_model/')
training_data = '/home/app/pipeline/train_data/NPDB_data.json'

# assign the inputs to the script variables
for current_argument, current_value in argument:
    if current_argument in ['-h','--help']:
        print("Usage: trainig-data: .json file path with the train data")
        print("       model: path to the universal background model (i.e.: en_core_web_sm)")
        print("       output-dir: folder path were the new model will be stored")
        print('.'*20)
    elif current_argument in ['-t', '--training-data']:
        training_data = str(current_value)
        print('Trainig file: '+ str(current_value))
        print('.'*20)
    elif current_argument in ['-m', '--model']:
        model = str(current_value)
        print('Base model directory: ' + str(current_value))

    elif current_argument in ['-o', '--output-dir']:
        output_dir = Path(str(current_value))
        print('Output directory: ' + str(current_value))



# transform the .json generated by the ner tool to spacy retrain code specs
def convert_dataturks_to_spacy(filename):
    with open(filename) as train_data:
        train = json.load(train_data)
    TRAIN_DATA = []
    for data in train:
	    ents = [tuple(entity) for entity in data['entities']]
	    TRAIN_DATA.append((data['content'],{'entities':ents}))  
    return TRAIN_DATA

try:
    TRAIN_DATA = convert_dataturks_to_spacy(training_data)
except:
    print('Error: Cant open the training data, check the file path')
    sys.exit(2)

TRAIN_DATA = TRAIN_DATA[:][:-1]


#               RETRAIN THE BASE MODEL
# check process time 
start_time = time.time()
# Optimal values: n_iter = 10, drop = 0.01

n_iter = 100
## Load model

#load the model
if model is not None:
    nlp = spacy.load(model)  
    print("Loaded model '%s' \n\n" % model)
else:
    nlp = spacy.blank('en')  
    print("Created blank 'en' model")

#set up the pipeline
if 'ner' not in nlp.pipe_names:
    ner = nlp.create_pipe('ner')
    nlp.add_pipe(ner, last=True)
else:
    ner = nlp.get_pipe('ner')

## Disable PIPELINE
for _, annotations in TRAIN_DATA:
    for ent in annotations.get('entities'):
        #print(ent[2])
        ner.add_label(ent[2])

other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']
with nlp.disable_pipes(*other_pipes):  # only train NER
    optimizer = nlp.begin_training()
    for itn in range(n_iter):
        random.shuffle(TRAIN_DATA)
        losses = {}
        for text, annotations in tqdm(TRAIN_DATA):
            nlp.update(
                [text],  
                [annotations],  
                drop=0.01,  
                sgd=optimizer,
                losses=losses)
        #print(losses)
print('.'*50)
print("--- %s seconds ---" % (time.time() - start_time))
print('.'*50)

if output_dir is not None:
    output_dir = Path(output_dir)
    if not output_dir.exists():
        output_dir.mkdir()
    nlp.to_disk(output_dir)
    print("Saved model to", output_dir)